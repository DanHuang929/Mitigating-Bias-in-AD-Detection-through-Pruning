# Mitigating Bias in MRI-Based Alzheimer's Disease Classifiers through Pruning of Deep Neural Networks

Part of the code about model pruning was selected from the following GitHub repository: https://github.com/i6092467/diff-bias-proxies.

## Abstract
With the increasing prevalence of Alzheimer's disease among the elderly population, the development of machine learning models for early identification is crucial. However, it has been observed that these models may exhibit inherent biases, leading to performance disparities across protected attributes such as age and gender. In this study, we propose a model pruning method aimed at reducing bias and achieving model fairness in a pre-trained neural network designed for Alzheimer's disease identification. Our pruning method takes into account both bias reduction and model performance. The results demonstrate that our proposed pruning method significantly reduces disparities between age and gender attributes compared to the baseline model. For disparity in age attributes, our method successfully reduces disparity across multiple metrics, such as true positive rate (-7.3%). Similarly, for gender attribute, our approach mitigated bias in evaluation metrics, such as true negative rate (-5.0%). The results also show that our method maintains or even improves the model's performance and outperforms other methods across most evaluation metrics.

## Introduction

Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by the degeneration of nerve cells and loss of brain tissue. Research has explored the potential of using machine learning (ML) models on MRI data for the diagnosis of AD. Dufumier et al. [1] combined y-aware metadata and contrastive learning for various binary classification tasks, including AD classification. Zhuang et al. [2] proposed a method inspired by solving a Rubik’s Cube, specifically designed for 3-dimensional (3D) medical images. Liu et al. [3] trained a stacked autoencoder to learn hidden representations followed by a softmax output layer for classification.

While ML models have shown promise in Alzheimer’s disease (AD) diagnosis using MRI data, it is essential to address potential biases in the training data. ML models heavily rely on the training data to minimize prediction errors, but biases related to race, gender, and age can impact predictions, leading to performance disparities. In some cases, the model may even worsen these biases, making it untrustworthy. To mitigate bias in ML models, various approaches have been proposed, including adversarial learning [4,5], model pruning [6,11], perturbation of loss functions [7], data preprocessing techniques [8,9], usage of multi-exit framework [12,13], and the use of multisource datasets [10]. However, simply reducing bias is not sufficient if it comes at the cost of a significant decrease in the overall performance of the model.

Our work extends the pruning method proposed in [6] to address its limitations. The existing method employs a stopping criterion based on bias reaching 0, but we found that insufficiently large pruning may have minimal impact on testing data. Additionally, the method incorporates another stopping criterion involving the model’s performance dropping below a predetermined threshold, but it does not ensure bias mitigation before the model’s performance determinesrates beyond the threshold. In our extension, we propose modifications to the pruning algorithm and fairness evaluation metric to enhance the method’s effectiveness in mitigating bias while maintaining model performance.

Our proposed method aims to maintain the model’s performance while allowing for the pruning of more neurons, which directly enhances the model’s debiasing capability. We measure fairness by evaluating the disparities across the protected attributes using metrics such as accuracy, area under the receiver operating characteristics (AUC), precision, true positive rate (TPR), true negative rate (TNR), and equalized odds. Additionally, we conduct a comparative analysis of our results with other model debiasing methods.

## Reference

1. Dufumier, B., Gori, P., Victor, J., Grigis, A., Wessa, M., Brambilla, P., Favre, P., Polosan, M., McDonald, C., Piguet, C.M., Duchesnay, E.: Contrastive Learning with Continuous Proxy MetaData for 3D MRI Classification, http://arxiv.org/abs/2106.08808, (2021). https://doi.org/10.48550/arXiv.2106.08808.
2. Zhuang, X., Li, Y., Hu, Y., Ma, K., Yang, Y., Zheng, Y.: Self-supervised Feature Learning for 3D Medical Images by Playing a Rubik’s Cube, http://arxiv.org/abs/1910.02241, (2019). https://doi.org/10.48550/arXiv.1910.02241.
3. Liu, S., Liu, S., Cai, W., Pujol, S., Kikinis, R., Feng, D.: Early diagnosis of Alzheimer’s disease with deep learning. In: 2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI). pp. 1015–1018 (2014). https://doi.org/10.1109/ISBI.2014.6868045.
4. Zhang, B.H., Lemoine, B., Mitchell, M.: Mitigating Unwanted Biases with Adversarial Learning. In: Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. pp. 335–340. ACM, New Orleans LA USA (2018). https://doi.org/10.1145/3278721.3278779.
5. Correa, R., Jeong, J.J., Patel, B., Trivedi, H., Gichoya, J.W., Banerjee, I.: Two-step adversarial debiasing with partial learning – medical image case-studies, http://arxiv.org/abs/2111.08711, (2021).
6. Marcinkevics, R., Ozkan, E., Vogt, J.E.: Debiasing Deep Chest X-Ray Classifiers using Intra- and Post-processing Methods. In: Proceedings of the 7th Machine Learning for Healthcare Conference. pp. 504–536. PMLR (2022).
7. Pfohl, S.R., Foryciarz, A., Shah, N.H.: An Empirical Characterization of Fair Machine Learning For Clinical Risk Prediction. Journal of Biomedical Informatics. 113, 103621 (2021). https://doi.org/10.1016/j.jbi.2020.103621.
8. Larrazabal, A.J., Nieto, N., Peterson, V., Milone, D.H., Ferrante, E.: Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis. Proceedings of the National Academy of Sciences. 117, 12592–12594 (2020). https://doi.org/10.1073/pnas.1919012117.
9. Petersen,E.,Feragen,A.,Zemsch,M.L.daC.,Henriksen,A.,Christensen,O.E.W., Ganz, M.: Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer’s disease detection, http://arxiv.org/abs/2204.01737, (2022).
10. Seyyed-Kalantari, L., Liu, G., McDermott, M., Chen, I.Y., Ghassemi, M.: CheXclusion: Fairness gaps in deep chest X-ray classifiers. In: Biocomputing 2021. pp. 232–243. WORLD SCIENTIFIC, Kohala Coast, Hawaii, USA (2020). https://doi.org/10.1142/9789811232701_0022.
11. Lin, X., Kim, S., Joo, J.: FairGRAPE: Fairness-Aware GRAdient Pruning mEthod for Face Attribute Classification. In: Avidan, S., Brostow, G., Cissé, M., Farinella, G.M., and Hassner, T. (eds.) Computer Vision – ECCV 2022. pp. 414–432. Springer Nature Switzerland, Cham (2022). https://doi.org/10.1007/978-3-031-19778-9_24.
12. Chiu, C.-H., Chung, H.-W., Chen, Y.-J., Shi, Y., Ho, T.-Y.: Toward Fairness Through Fair Multi-Exit Framework for Dermatological Disease Diagnosis, http://arxiv.org/abs/2306.14518, (2023). https://doi.org/10.48550/arXiv.2306.14518.
13. Chiu, C.-H., Chung, H.-W., Chen, Y.-J., Shi, Y., Ho, T.-Y.: Fair Multi-Exit Framework for Facial Attribute Classification, http://arxiv.org/abs/2301.02989, (2023).
14. Hardt, M., Price, E., Srebro, N.: Equality of Opportunity in Supervised Learning, http://arxiv.org/abs/1610.02413,(2016). https://doi.org/10.48550/arXiv.1610.02413.
15. Savani, Y., White, C., Govindarajulu, N.S.: Intra-Processing Methods for Debiasing Neural Networks. In: Advances in Neural Information Processing Systems. pp. 2798–2810. Curran Associates, Inc. (2020).

